{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 15\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"Create a pre-trained model and add a few layers to it.\n",
    "    \n",
    "    Returns:\n",
    "        model (Model): A pre-trained model with a few layers added on top\n",
    "    \"\"\"\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, test_path, validation_path, epochs=1, batch_size=32):\n",
    "    \"\"\"Train the model.\n",
    "    \n",
    "    Args:\n",
    "        model (Model): A pre-trained model with a few layers added on top\n",
    "        test_path (string): Path to the directory that contains the test set\n",
    "        validation_path (string): Path to the directory that contains the validation set\n",
    "        epochs (int): Number of epochs to train the model\n",
    "\n",
    "    Returns:\n",
    "        model (Model): A trained model\n",
    "    \"\"\"\n",
    "\n",
    "    train_dataset = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    train_dataset = train_dataset.flow_from_directory(      test_path,\n",
    "                                                            target_size=(224, 224),\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            class_mode='categorical')\n",
    "\n",
    "    validation_dataset = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    validation_dataset = validation_dataset.flow_from_directory(validation_path,\n",
    "                                                            target_size=(224, 224),\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            class_mode='categorical')\n",
    "\n",
    "\n",
    "    # freeze all layers in the base model\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # train the model on the new data for a few epochs\n",
    "    model.fit_generator(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_dataset,\n",
    "        validation_steps=800 // batch_size)\n",
    "\n",
    "    # unfreeze the last few layers of the base model\n",
    "    for layer in model.layers[-5:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # we need to recompile the model for these modifications to take effect\n",
    "    # we use SGD with a low learning rate\n",
    "    model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "    # alongside the top Dense layers\n",
    "    model.fit_generator(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_dataset,\n",
    "        validation_steps=800 // batch_size)\n",
    "\n",
    "    # save the model\n",
    "    model.save('mobilenetv2.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, validation_path, batch_size=32):\n",
    "    \"\"\"Evaluate the model\n",
    "    \n",
    "    Args:\n",
    "        model (Model): A trained model\n",
    "\n",
    "    Returns:\n",
    "        ndarray: A numpy array containing the loss and accuracy of the model\n",
    "    \"\"\"\n",
    "    validation_dataset = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    validation_dataset = validation_dataset.flow_from_directory(validation_path,\n",
    "                                                            target_size=(224, 224),\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            class_mode='categorical')\n",
    "                                                            \n",
    "    return model.evaluate_generator(validation_dataset, steps=800 // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "705981ebfef8414934dd4135383ecdf26fe8fa6933659ee4e9a6df233986ed45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
