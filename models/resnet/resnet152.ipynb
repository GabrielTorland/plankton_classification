{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 00:13:17.215590: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-23 00:13:20.469437: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-23 00:13:20.858770: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-23 00:13:20.858784: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-23 00:13:25.752713: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-23 00:13:25.752807: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-23 00:13:25.752810: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from resnet_models import create_resnet152_model, create_resnet152v2_model\n",
    "import wandb\n",
    "import os\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data Set\n",
    "Three sets are created: training, validation, and test. \n",
    "- Labels are generated based on the folder structure. Class name must correspond to the subfolder name.\n",
    "- Loading in batches, of size 32, to reduce memory usage.\n",
    "- Label mode is set to categorical, which means that the labels are encoded as a categorical vector.\n",
    "\n",
    "Bilinear interploation is set to default. This specify the method used in the resizing procedure. By default aspect ratio is not perserved, i.e., the ratio between image width and height.\n",
    "\n",
    "One hot encoding is utilized when label mode is set to categorical.\n",
    "\n",
    "\n",
    "The image load documentation is available [here](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory) and an example is available [here](https://keras.io/api/data_loading/image/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory=\"dataset/train\",\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224)\n",
    "    )\n",
    "val_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory=\"dataset/val\",\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224)\n",
    "    )\n",
    "test_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory=\"dataset/test\",\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    shuffle=False,\n",
    "    batch_size= 32,\n",
    "    image_size=(224, 224)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize wandb\n",
    "wandb.init(project=\"ResNet152\", config={\"learning_rate\": 0.001, \"epochs\": 30, \"verbose\": 1,\"name\": \"ResNet152\", \"architecture\": \"ResNet152\"})\n",
    "\n",
    "# configs\n",
    "cfg = wandb.config\n",
    "\n",
    "# create the model\n",
    "model = create_resnet152_model(len(train_ds.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of callbacks\n",
    "callbacks = [\n",
    "            WandbCallback(mode=\"min\", monitor=\"val_loss\", save_graph=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=3, min_lr=0.00001),\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5),\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs=cfg.epochs, batch_size=32, verbose=cfg.verbose, validation_data=val_ds, callbacks=callbacks) # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
