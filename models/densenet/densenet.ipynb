{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9246da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from densenet_models import create_densenet121_model, create_densenet169_model, create_densenet201_model\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cd55ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22340 files belonging to 15 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 02:46:13.568898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 137 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB, pci bus id: 0000:bc:00.0, compute capability: 7.0\n",
      "2023-03-18 02:46:13.597487: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 137.44M (144113664 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'baseline_training_set_old/val'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/andreaspr/plankton_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[1;32m      3\u001b[0m     directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaseline_training_set_old/train\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minferred\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[1;32m      9\u001b[0m     )\n\u001b[0;32m---> 10\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbaseline_training_set_old/val\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minferred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m test_ds \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[1;32m     19\u001b[0m     directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaseline_training_set_old/test\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minferred\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[1;32m     25\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image_dataset.py:190\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m   seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n\u001b[0;32m--> 190\u001b[0m image_paths, labels, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALLOWLIST_FORMATS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    200\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    201\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen passing `label_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, there must exactly 2 classes. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    202\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound the following classes: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (class_names,))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/preprocessing/dataset_utils.py:66\u001b[0m, in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m   subdirs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 66\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m     68\u001b[0m       subdirs\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'baseline_training_set_old/val'"
     ]
    }
   ],
   "source": [
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory=\"dataset/train\",\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224)\n",
    "    )\n",
    "val_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory=\"dataset/val\",\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224)\n",
    "    )\n",
    "test_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory=\"dataset/test\",\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    shuffle=False,\n",
    "    batch_size= 32,\n",
    "    image_size=(224, 224)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c224f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of callbacks\n",
    "callbacks = [\n",
    "            WandbCallback(mode=\"min\", monitor=\"val_loss\", save_graph=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=3, min_lr=0.00001),\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5),\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d59f6",
   "metadata": {},
   "source": [
    "# DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf1c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize wandb\n",
    "wandb.init(project=\"DenseNet\", config={\"learning_rate\": 0.001, \"epochs\": 30, \"verbose\": 1,\"name\": \"DenseNet121\", \"architecture\": \"DenseNet121\"})\n",
    "\n",
    "# configs\n",
    "cfg = wandb.config\n",
    "\n",
    "# create the model\n",
    "model = create_densenet121_model(len(train_ds.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs=cfg.epochs, batch_size=32, verbose=cfg.verbose, validation_data=val_ds, callbacks=callbacks) # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b067ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e136fb",
   "metadata": {},
   "source": [
    "# DenseNet169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b10c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize wandb\n",
    "wandb.init(project=\"DenseNet\", config={\"learning_rate\": 0.001, \"epochs\": 30, \"verbose\": 1,\"name\": \"DenseNet169\", \"architecture\": \"DenseNet169\"})\n",
    "\n",
    "# configs\n",
    "cfg = wandb.config\n",
    "\n",
    "# create the model\n",
    "model = create_densenet169_model(len(train_ds.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b95472",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs=cfg.epochs, batch_size=32, verbose=cfg.verbose, validation_data=val_ds, callbacks=callbacks) # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e775f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95816dbc",
   "metadata": {},
   "source": [
    "# DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e49a417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize wandb\n",
    "wandb.init(project=\"DenseNet\", config={\"learning_rate\": 0.001, \"epochs\": 30, \"verbose\": 1,\"name\": \"DenseNet201\", \"architecture\": \"DenseNet201\"})\n",
    "\n",
    "# configs\n",
    "cfg = wandb.config\n",
    "\n",
    "# create the model\n",
    "model = create_densenet201_model(len(train_ds.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66238ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs=cfg.epochs, batch_size=32, verbose=cfg.verbose, validation_data=val_ds, callbacks=callbacks) # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd470aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "705981ebfef8414934dd4135383ecdf26fe8fa6933659ee4e9a6df233986ed45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
